{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A03: Detecting Spelling Errors, Minimum Edit Distance, Human Morphology and Sentiment Analysis with Naïve Bayesian Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                    By Besnik Balaj & Amanda Ly\n",
    "I plege my honor that I have abided by the Stevens Honor System \n",
    "                      -Amanda Ly & Besnik Balaj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deliverables: \n",
    "\n",
    "1. Respond to J&M 2nd Exercises 3.10 and 3.11.\n",
    "\n",
    "2. Find Python packages that apply Bayesian logic to classification and apply one to sentiment data. Such data can be downloaded from Amazon which collects reviews from customers, and possibly specialized rating sites for electronics, entertainment, restaurants, and other products and services. A sentiment data set using Amazon data is available with papers that report on research using it from here (Links to an external site.).\n",
    "\n",
    "3. Briefly report on SentiWordNet (Links to an external site.) and how it can be used with Python and WordNet to classify a corpus of reviews (tweets are not easy to get right since they do not use “natural” language). Do not get bogged down preparing the reviews for analysis. It is acceptable to find a research paper (Links to an external site.) or blog that reports on such use.\n",
    "\n",
    "4. Respond to the Bayesian part of BKL Exercise 6.3. Entire exercise can be a project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where to Look:\n",
    "- J&M 2nd Edition on Chapter 3 \n",
    "- J&M 3rd Edition on Chapter 4\n",
    "- A&S Chapter 2 \n",
    "- BKL Section 6.5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. J&M 2nd Edition Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.10 :\n",
    "Computing Minimum Edit Distance by hand, find out whether drive is closer to brief or to divers, and what the edit distance is. You may use any version of distance you like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equations:\n",
    "\n",
    "    D[i,j] = MIN { D[i−1,j] +1 \n",
    "                    D[i,j−1] +1\n",
    "                    D[i−1,j−1] + {2; if source[i] /= target[j]\n",
    "                                  0; if source[i] = target[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this question, I am using insertion cost 1, deletion cost 1, and subsitution cost 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Edit Distance Grid: drive vs divers\n",
    " \n",
    "          d  r  i  v  e\n",
    "       0  1  2  3  4  5\n",
    "    d  1  0  1  2  3  4  \n",
    "    i  2  1  2  1  2  3      \n",
    "    v  3  2  3  2  1  2    \n",
    "    e  4  3  4  3  2  1    \n",
    "    r  5  4  3  4  3  2\n",
    "    s  6  5  4  5  4  3\n",
    " \n",
    " The minimum edit distance is 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit Distance Grid: drive vs divers\n",
    " \n",
    "          d  r  i  v  e\n",
    "       0  1  2  3  4  5\n",
    "    b  1  2  3  4  5  6      \n",
    "    r  2  3  2  3  4  5      \n",
    "    i  3  4  3  2  3  4      \n",
    "    e  4  5  4  3  4  3     \n",
    "    f  5  6  5  4  5  4\n",
    "The minimum edit distance is 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore divers is closer to drive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/image2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.11:\n",
    "Now implement a minimum edit distance algorithim and use your hand computed results to check your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From DRIVE to BRIEF we achieve an Edit Distance of 3\n",
      "From DRIVE to DIVERS we achieve an Edit Distance of 3\n",
      "So here we see an issue of assuming Replacement to be the cost of just 1 instead of 2 (where it is a combination of Delete and insert). We see DRIVE is possibly similar to both equally but that can't be the case.So let us see what happens from our handwork above. When DRIVE goes to BRIEF we are Deleting D and Inserting B followed by a Deletion of V and Insertion of F.From DRIVE to DIVERS we have a Deleting of R, an Inserting of R and an Inserting of S. Thus 1 less step and specifcally a less perplex step of an immediate removal and insert. Therefore the perplexity would need to be taken account.\n"
     ]
    }
   ],
   "source": [
    "#https://www.geeksforgeeks.org/edit-distance-dp-5/ <--Where I got code but wish to update something\n",
    "def editDistance(str1, str2, m , n): \n",
    "    if m==0: \n",
    "         return n \n",
    "    if n==0: \n",
    "        return m \n",
    "    if str1[m-1]==str2[n-1]: \n",
    "        return editDistance(str1,str2,m-1,n-1) \n",
    "    return 1 + min(editDistance(str1, str2, m, n-1),    # Insert \n",
    "                   editDistance(str1, str2, m-1, n),    # Remove \n",
    "                   editDistance(str1, str2, m-1, n-1)    # Replace \n",
    "                   ) \n",
    "\n",
    "str1 = \"DRIVE\"\n",
    "str2 = \"BRIEF\"\n",
    "str3 = \"DIVERS\"\n",
    "DtoB = editDistance(str1, str2, len(str1), len(str2))\n",
    "DtoD = editDistance(str1, str3, len(str1), len(str3))\n",
    "print(f\"From DRIVE to BRIEF we achieve an Edit Distance of {DtoB}\")\n",
    "print(f\"From DRIVE to DIVERS we achieve an Edit Distance of {DtoD}\")\n",
    "print(\"So here we see an issue of assuming Replacement to be the cost of just 1 instead of 2 (where it is a combination of Delete and insert). We see DRIVE is possibly similar to both equally but that can't be the case.\"\n",
    "      \"So let us see what happens from our handwork above. When DRIVE goes to BRIEF we are Deleting D and Inserting B followed by a Deletion of V and Insertion of F.\"\n",
    "      \"From DRIVE to DIVERS we have a Deleting of R, an Inserting of R and an Inserting of S. Thus 1 less step and specifcally a less perplex step of an immediate removal and insert. Therefore the perplexity would need to be taken account.\"\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From DRIVE to BRIEF is 3.0\n",
      "From DRIVE to DIVERS is 3.0\n"
     ]
    }
   ],
   "source": [
    "#https://stackabuse.com/levenshtein-distance-and-text-similarity-in-python/\n",
    "#Another implementation here\n",
    "import numpy as np\n",
    "\n",
    "def levenshtein(seq1, seq2):\n",
    "    size_x = len(seq1) + 1\n",
    "    size_y = len(seq2) + 1\n",
    "    matrix = np.zeros ((size_x, size_y))\n",
    "    for x in range(size_x):\n",
    "        matrix [x, 0] = x\n",
    "    for y in range(size_y):\n",
    "        matrix [0, y] = y\n",
    "\n",
    "    for x in range(1, size_x):\n",
    "        for y in range(1, size_y):\n",
    "            if seq1[x-1] == seq2[y-1]:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1, y] + 1,\n",
    "                    matrix[x-1, y-1],\n",
    "                    matrix[x, y-1] + 1\n",
    "                )\n",
    "            else:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1,y] + 1,\n",
    "                    matrix[x-1,y-1] + 1,\n",
    "                    matrix[x,y-1] + 1\n",
    "                )\n",
    "    #print (matrix)\n",
    "    return (matrix[size_x - 1, size_y - 1])\n",
    "\n",
    "print(f\"From DRIVE to BRIEF is {levenshtein(str1,str2)}\")\n",
    "print(f\"From DRIVE to DIVERS is {levenshtein(str1,str3)}\")\n",
    "print(\"This is just another case of cost being set to 1, an incorrect thought\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From DRIVE to BRIEF is 4\n",
      "From DRIVE to DIVERS is 3\n",
      "And here we can see that when we assume cost to potentially be 2 for subsition or 0, we get a clearer and correct re-sult\n"
     ]
    }
   ],
   "source": [
    "def LD(s, t):\n",
    "    if s == \"\":\n",
    "        return len(t)\n",
    "    if t == \"\":\n",
    "        return len(s)\n",
    "    if s[-1] == t[-1]:\n",
    "        cost = 0\n",
    "    else:\n",
    "        cost = 2\n",
    "       \n",
    "    res = min([LD(s[:-1], t)+1,\n",
    "               LD(s, t[:-1])+1, \n",
    "               LD(s[:-1], t[:-1]) + cost])\n",
    "    return res\n",
    "print(f\"From DRIVE to BRIEF is {LD(str1,str2)}\")\n",
    "print(f\"From DRIVE to DIVERS is {LD(str1,str3)}\")\n",
    "print(\"And here we can see that when we assume cost to potentially be 2 for subsition or 0, we get a clearer and correct re-sult\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Bayesian Logic Package and Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find Python packages that apply Bayesian logic to classification and apply one to sentiment data. Such data can be downloaded from Amazon which collects reviews from customers, and possibly specialized rating sites for electronics, entertainment, restaurants, and other products and services. A sentiment data set using Amazon data is available with papers that report on research using it from here (Links to an external site.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find package and import/get it here\n",
    "#Describe what it do ya kno and test it \n",
    "#link for tests: https://www.cs.jhu.edu/~mdredze/datasets/sentiment/ ITS TARS! YAYYYYYY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Report on SentiWordNet and its use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Briefly report on SentiWordNet (Links to an external site.) and how it can be used with Python and WordNet to classify a corpus of reviews (tweets are not easy to get right since they do not use “natural” language). Do not get bogged down preparing the reviews for analysis. It is acceptable to find a research paper (Links to an external site.) or blog that reports on such use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PUT DISCUSSION HERE\n",
    "#LINK HERE: https://www.researchgate.net/publication/267249616_Reviews_Classification_Using_SentiWordNet_Lexicon RESEARCH!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Bayesian part of BKL Exercise 6.3  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Senseval 2 Corpus contains data intended to train word-sense disambigua-tion classifiers. It contains data for four words: hard, interest, line, and serve. Choose one of these four words, and load the corresponding data:  \n",
    "\n",
    "- from nltk.corpus import senseval\n",
    "- instances = senseval.instances('hard.pos')\n",
    "- size = int(len(instances) * 0.1)\n",
    "- train_set, test_set = instances[size:], instances[:size]\n",
    "\n",
    "Using this dataset, build a classifier that predicts the correct sense tag for a given instance. See the corpus HOWTO at http://www.nltk.org/howto for informationon using the instance objects returned by the Senseval 2 Corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
